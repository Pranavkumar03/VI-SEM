{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45406481-6b29-4272-9915-b56f70c857b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1f65c25-770c-4a43-a7d4-068b3f040de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([2.0,4.0])\n",
    "y=torch.tensor([20.0,40.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "197f55ef-5801-4eb1-9f87-229563077e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(1.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "lr = torch.tensor(0.001)\n",
    "loss_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0067e63c-5383-4823-822e-6e652d4bf0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Gradient: w.grad = -174.0, b.grad = -52.0\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "\n",
    "w_grad_analytical = (2/N) * torch.sum((w * x + b - y) * x)\n",
    "b_grad_analytical = (2/N) * torch.sum(w * x + b - y)\n",
    "print(f\"Analytical Gradient: w.grad = {w_grad_analytical.item()}, b.grad = {b_grad_analytical.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfab2bca-ac3f-4354-b77a-f4e49186e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-174.) tensor(-52.)\n",
      "parameters w=1.1740000247955322,b=1.0520000457763672,loss=757.0\n",
      "tensor(-170.2080) tensor(-50.8520)\n",
      "parameters w=1.344208002090454,b=1.1028521060943604,loss=724.3797607421875\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    loss = 0.0\n",
    "    for i in range(len(x)):\n",
    "        a = w * x[i]\n",
    "        y_p = a + b\n",
    "        loss += (y_p - y[i]) ** 2\n",
    "    loss = loss / len(x)\n",
    "    loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        print(w.grad,b.grad)\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    print(\"parameters w={},b={},loss={}\".format(w,b,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a29dc-f6ba-4a11-95fe-5905b9b92db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
