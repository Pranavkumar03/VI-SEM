{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973d9a00-f865-4bdc-bcfe-75ac0a9e656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2400e3ae-f797-4a37-b857-beeb1e8649e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.4484, 0.3055, 0.4146, 0.9176, 0.7463, 0.1463],\n",
      "        [0.3340, 0.1089, 0.1755, 0.0778, 0.2820, 0.5794],\n",
      "        [0.8159, 0.3322, 0.3956, 0.1398, 0.1719, 0.2753],\n",
      "        [0.2863, 0.3960, 0.9490, 0.4262, 0.2704, 0.5056],\n",
      "        [0.2451, 0.6562, 0.7351, 0.6890, 0.1379, 0.4192],\n",
      "        [0.1292, 0.1849, 0.2498, 0.8136, 0.4093, 0.8681]])\n"
     ]
    }
   ],
   "source": [
    "image=torch.rand(6,6)\n",
    "print(\"image=\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8383b277-03e8-4da5-b7ba-e4709fa6938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape= torch.Size([1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "image=image.unsqueeze(dim=0)\n",
    "print(\"image shape=\",image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e134222-b592-4c6e-be12-ff190b5b2bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape= torch.Size([1, 1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "image=image.unsqueeze(dim=0)\n",
    "print(\"image shape=\",image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b591f99-e9bb-41b1-afe6-62537f0c9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[[[0.4484, 0.3055, 0.4146, 0.9176, 0.7463, 0.1463],\n",
      "          [0.3340, 0.1089, 0.1755, 0.0778, 0.2820, 0.5794],\n",
      "          [0.8159, 0.3322, 0.3956, 0.1398, 0.1719, 0.2753],\n",
      "          [0.2863, 0.3960, 0.9490, 0.4262, 0.2704, 0.5056],\n",
      "          [0.2451, 0.6562, 0.7351, 0.6890, 0.1379, 0.4192],\n",
      "          [0.1292, 0.1849, 0.2498, 0.8136, 0.4093, 0.8681]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"image=\",image)\n",
    "kernel=torch.ones(3,3)\n",
    "print(\"kernel=\",kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa0cbc5-e764-4103-9412-b1a4624601cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=kernel.unsqueeze(dim=0)\n",
    "kernel=kernel.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee82be5-798c-4643-8de0-ea12702ca02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[3.3306, 2.8675, 3.3212, 3.3364],\n",
      "          [3.7935, 3.0011, 2.8883, 2.7284],\n",
      "          [4.8114, 4.7192, 3.9150, 3.0353],\n",
      "          [3.8316, 5.0998, 4.6802, 4.5393]]]]) outputshapetorch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "outimage=F.conv2d(image,kernel,stride=1,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage,outimage.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1c40d4-36f5-4118-880e-4b23e5e7dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[3.3306, 3.3364],\n",
      "          [3.8316, 4.5393]]]]) outputshapetorch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "outimage1=F.conv2d(image,kernel,stride=3,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage1,outimage1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c8f7bd-3774-45bf-9e88-1d5f1a0300b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[0.4484, 0.7538, 1.1684, 1.6376, 2.0785, 1.8102, 0.8926, 0.1463],\n",
      "          [0.7824, 1.1968, 1.7869, 1.9999, 2.6138, 2.7494, 1.7540, 0.7257],\n",
      "          [1.5983, 2.3449, 3.3306, 2.8675, 3.3212, 3.3364, 2.2012, 1.0009],\n",
      "          [1.4361, 2.2733, 3.7935, 3.0011, 2.8883, 2.7284, 2.0846, 1.3602],\n",
      "          [1.3472, 2.7316, 4.8114, 4.7192, 3.9150, 3.0353, 1.7803, 1.2001],\n",
      "          [0.6605, 1.8977, 3.8316, 5.0998, 4.6802, 4.5393, 2.6105, 1.7930],\n",
      "          [0.3742, 1.2154, 2.2003, 3.3286, 3.0346, 3.3371, 1.8345, 1.2874],\n",
      "          [0.1292, 0.3141, 0.5639, 1.2483, 1.4726, 2.0910, 1.2774, 0.8681]]]]) outputshapetorch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "outimage2=F.conv2d(image,kernel,stride=1,padding=2)\n",
    "print(\"outimage{} outputshape{}\".format(outimage2,outimage2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04409f16-9a4d-4309-814c-87fc18b62976",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1=torch.ones(4,4)\n",
    "kernel1=kernel1.unsqueeze(dim=0)\n",
    "kernel1=kernel1.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c676e9-744c-4f1a-8ad7-13966d10632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[6.5232, 6.1094, 6.4733],\n",
      "          [6.7627, 5.9437, 6.2298],\n",
      "          [7.4438, 6.9569, 7.4558]]]]) outputshapetorch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "outimage3=F.conv2d(image,kernel1,stride=1,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage3,outimage3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f031d929-9df0-4d3e-9e1f-1bb278ec97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def hout(hin,k,stride,pad):\n",
    "    return math.floor((hin-k+2*pad)/stride)+1\n",
    "hout(6,3,2,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d44697-328c-4d6e-8f44-34e697f978a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m conv_layer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m output_torch_conv2d \u001b[38;5;241m=\u001b[39m conv_layer(image)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput from torch.nn.Conv2d:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_torch_conv2d)\n\u001b[1;32m     10\u001b[0m kernel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "output_torch_conv2d = conv_layer(image)\n",
    "print(\"Output from torch.nn.Conv2d:\", output_torch_conv2d)\n",
    "\n",
    "kernel = torch.ones(3, 3, 1, 3)  \n",
    "output_functional_conv2d = F.conv2d(image, kernel, stride=1, padding=0)\n",
    "print(\"Output from torch.nn.functional.conv2d:\", output_functional_conv2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915252f9-5a25-4082-8475-984419cef9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
