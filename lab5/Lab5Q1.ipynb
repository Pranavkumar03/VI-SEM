{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "973d9a00-f865-4bdc-bcfe-75ac0a9e656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2400e3ae-f797-4a37-b857-beeb1e8649e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[0.4484, 0.3055, 0.4146, 0.9176, 0.7463, 0.1463],\n",
      "        [0.3340, 0.1089, 0.1755, 0.0778, 0.2820, 0.5794],\n",
      "        [0.8159, 0.3322, 0.3956, 0.1398, 0.1719, 0.2753],\n",
      "        [0.2863, 0.3960, 0.9490, 0.4262, 0.2704, 0.5056],\n",
      "        [0.2451, 0.6562, 0.7351, 0.6890, 0.1379, 0.4192],\n",
      "        [0.1292, 0.1849, 0.2498, 0.8136, 0.4093, 0.8681]])\n"
     ]
    }
   ],
   "source": [
    "image=torch.rand(6,6)\n",
    "print(\"image=\",image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8383b277-03e8-4da5-b7ba-e4709fa6938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape= torch.Size([1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "image=image.unsqueeze(dim=0)\n",
    "print(\"image shape=\",image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e134222-b592-4c6e-be12-ff190b5b2bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape= torch.Size([1, 1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "image=image.unsqueeze(dim=0)\n",
    "print(\"image shape=\",image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b591f99-e9bb-41b1-afe6-62537f0c9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image= tensor([[[[0.4484, 0.3055, 0.4146, 0.9176, 0.7463, 0.1463],\n",
      "          [0.3340, 0.1089, 0.1755, 0.0778, 0.2820, 0.5794],\n",
      "          [0.8159, 0.3322, 0.3956, 0.1398, 0.1719, 0.2753],\n",
      "          [0.2863, 0.3960, 0.9490, 0.4262, 0.2704, 0.5056],\n",
      "          [0.2451, 0.6562, 0.7351, 0.6890, 0.1379, 0.4192],\n",
      "          [0.1292, 0.1849, 0.2498, 0.8136, 0.4093, 0.8681]]]])\n",
      "kernel= tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"image=\",image)\n",
    "kernel=torch.ones(3,3)\n",
    "print(\"kernel=\",kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa0cbc5-e764-4103-9412-b1a4624601cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel=kernel.unsqueeze(dim=0)\n",
    "kernel=kernel.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee82be5-798c-4643-8de0-ea12702ca02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[3.3306, 2.8675, 3.3212, 3.3364],\n",
      "          [3.7935, 3.0011, 2.8883, 2.7284],\n",
      "          [4.8114, 4.7192, 3.9150, 3.0353],\n",
      "          [3.8316, 5.0998, 4.6802, 4.5393]]]]) outputshapetorch.Size([1, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "outimage=F.conv2d(image,kernel,stride=1,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage,outimage.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc1c40d4-36f5-4118-880e-4b23e5e7dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[3.3306, 3.3364],\n",
      "          [3.8316, 4.5393]]]]) outputshapetorch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "outimage1=F.conv2d(image,kernel,stride=3,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage1,outimage1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69c8f7bd-3774-45bf-9e88-1d5f1a0300b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[0.4484, 0.7538, 1.1684, 1.6376, 2.0785, 1.8102, 0.8926, 0.1463],\n",
      "          [0.7824, 1.1968, 1.7869, 1.9999, 2.6138, 2.7494, 1.7540, 0.7257],\n",
      "          [1.5983, 2.3449, 3.3306, 2.8675, 3.3212, 3.3364, 2.2012, 1.0009],\n",
      "          [1.4361, 2.2733, 3.7935, 3.0011, 2.8883, 2.7284, 2.0846, 1.3602],\n",
      "          [1.3472, 2.7316, 4.8114, 4.7192, 3.9150, 3.0353, 1.7803, 1.2001],\n",
      "          [0.6605, 1.8977, 3.8316, 5.0998, 4.6802, 4.5393, 2.6105, 1.7930],\n",
      "          [0.3742, 1.2154, 2.2003, 3.3286, 3.0346, 3.3371, 1.8345, 1.2874],\n",
      "          [0.1292, 0.3141, 0.5639, 1.2483, 1.4726, 2.0910, 1.2774, 0.8681]]]]) outputshapetorch.Size([1, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "outimage2=F.conv2d(image,kernel,stride=1,padding=2)\n",
    "print(\"outimage{} outputshape{}\".format(outimage2,outimage2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04409f16-9a4d-4309-814c-87fc18b62976",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1=torch.ones(4,4)\n",
    "kernel1=kernel1.unsqueeze(dim=0)\n",
    "kernel1=kernel1.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9c676e9-744c-4f1a-8ad7-13966d10632a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outimagetensor([[[[6.5232, 6.1094, 6.4733],\n",
      "          [6.7627, 5.9437, 6.2298],\n",
      "          [7.4438, 6.9569, 7.4558]]]]) outputshapetorch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "outimage3=F.conv2d(image,kernel1,stride=1,padding=0)\n",
    "print(\"outimage{} outputshape{}\".format(outimage3,outimage3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f031d929-9df0-4d3e-9e1f-1bb278ec97b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def hout(hin,k,stride,pad):\n",
    "    return math.floor((hin-k+2*pad)/stride)+1\n",
    "hout(6,3,1,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3da2fd0b-50f2-4b23-8263-15835fa2da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from torch.nn.Conv2d: tensor([[[[ 0.0192,  0.0379, -0.1003, -0.2146],\n",
      "          [-0.0148,  0.1930,  0.1012, -0.0502],\n",
      "          [-0.1311, -0.0302,  0.2019, -0.0834],\n",
      "          [-0.1926, -0.2290,  0.1110, -0.0047]],\n",
      "\n",
      "         [[ 0.2497,  0.1873,  0.3089,  0.3773],\n",
      "          [ 0.0702,  0.0666,  0.2250,  0.0775],\n",
      "          [ 0.3729,  0.2902,  0.3897,  0.2438],\n",
      "          [ 0.3708,  0.3235,  0.3532,  0.2341]],\n",
      "\n",
      "         [[ 0.8794,  0.8659,  1.0218,  0.8714],\n",
      "          [ 0.6730,  0.6620,  0.7460,  0.8293],\n",
      "          [ 1.1164,  0.7828,  0.6090,  0.7285],\n",
      "          [ 0.8459,  0.9310,  0.6848,  1.0345]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Output from torch.nn.functional.conv2d: tensor([[[[3.3306, 2.8675, 3.3212, 3.3364],\n",
      "          [3.7935, 3.0011, 2.8883, 2.7284],\n",
      "          [4.8114, 4.7192, 3.9150, 3.0353],\n",
      "          [3.8316, 5.0998, 4.6802, 4.5393]],\n",
      "\n",
      "         [[3.3306, 2.8675, 3.3212, 3.3364],\n",
      "          [3.7935, 3.0011, 2.8883, 2.7284],\n",
      "          [4.8114, 4.7192, 3.9150, 3.0353],\n",
      "          [3.8316, 5.0998, 4.6802, 4.5393]],\n",
      "\n",
      "         [[3.3306, 2.8675, 3.3212, 3.3364],\n",
      "          [3.7935, 3.0011, 2.8883, 2.7284],\n",
      "          [4.8114, 4.7192, 3.9150, 3.0353],\n",
      "          [3.8316, 5.0998, 4.6802, 4.5393]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "kernelx = torch.ones(3, 1, 3, 3)  \n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
    "output_torch_conv2d = conv_layer(image)\n",
    "print(\"Output from torch.nn.Conv2d:\", output_torch_conv2d)\n",
    "\n",
    "output_functional_conv2d = F.conv2d(image, kernelx, stride=1, padding=0)\n",
    "print(\"Output from torch.nn.functional.conv2d:\", output_functional_conv2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2dc75da6-97ee-4c58-a579-14fee674d386",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'builtin_function_or_method' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kernel\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m+\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'builtin_function_or_method' and 'int'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c9384-ef6b-423f-9a3c-f9b9e55d5439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
